---
layout: post
title: "HDFS"
---

### Background
* store very large data sets reliably
* streaming at high bandwidth
* large cluster
* Directly attached storage

### Details

#### NameNode
* format NameNode
    * to create a file system instance, which is persistently stored on all nodes of the cluster
    * different cluster has different ID
* write data
    * NameNode nominate threee DataNodes
    * client writes them in a pipeline fashion
* restart
    1. NameNode initializes the namespace image from the checkpoint
    - replay the journal log, which locates in local host native file system

#### DataNode
* start
    1. handshake to verify *namespace ID* and software version
    - register a *storage ID* for identifying DataNode
* live heartbeat
    * sent *block report* to NameNode every hour
    * heartbeat every 3s, 10 minutes are considered out of service
    * NameNode instructions are on replies of heartbeat

#### Image and Journal
* The namespace image is the file system metadata that describes the organization of application data as directories and files
* A persistent record of the image written to disk is called a *checkpoint*
    * it would be stored in multiple directories, e.g., in different volumes
    * once namespace information lost, it would be lost partly or entirely
    * if error on writing journal to one of the storage directories, it excludes that directory from the list of storage directories
    * NameNode shuts down if no storage directory is available
* Batch commits for multithreaded system
    * multiple transactions would be commited together to get rid of flush-and-sync operation

#### Checkpoint Node
* usually another node would read the checkpoint with journal to get a new checkpoint

#### Upgrade and Snapshot
* Snapshot creation is an all-cluster effort rather than a node-selective event
    * NameNode would create a new checkpoint
    * DataNode would copy-on-write: create a copy of storage directories with hard links
* On upgrade failure
    1. the namespace would roll back
    - NameNode would not recognize new files, new files on DataNodes would be deleted

#### Block Placement
* No DataNode contains > 1 replica of any block
* No rack contains > 2 replicas of the same block, provided there are sufficient racks

### Problems
* No authentications, file permissions -> use Kerberos
* Directory sub-tree should have quota
