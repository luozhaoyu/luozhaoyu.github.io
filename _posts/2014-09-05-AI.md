---
layout: post
title: "AI"
---

* engineering approach than algorithm
### Course Main Topics
* Learning from Data
* View problem solving as heruristic search through a large space of possible solutions
* Use probabilistic reasoning and learning
* Use logical reasoning -- representing knowledge about the world in computers
* Neural networks
* Philosophical Foundation of AI

### Class Mottos so far
* Generalize do not memorize
* Let the data decide

### ID3 Algorithms
base cases
* overfitting
* Decision-forests
* Pruning decision-trees

1. no examples left, return majority class at parent as leaf
- all examples same category, return leaf with that category
- no features left, returning majority class in examples as leaf

recursive case
* choose the best feature and use it label an interior node
* recur on each possible value of the chosen feature

### General ML issues covered
* supervised ML, e.g. examples have labels
* fixed-length feature vectors, 99.9% pratical way
* info theory/ gain/ needed/ remaining
* expected_value calculations
* overfitting reduction
* TRAIN/ TUNE/ TEST sets
* [Ensemble] (http://en.wikipedia.org/wiki/Ensemble_learning)
    * Why not learn multiple models? Which works well and is work
    * Why not score only a small subset of the candidate features
    * [bagging] (http://en.wikipedia.org/wiki/Bootstrap_aggregating)
    * [boosting] (http://en.wikipedia.org/wiki/Boosting_(machine_learning))
* [learning curve] (http://en.wikipedia.org/wiki/Learning_curve#In_machine_learning)

### Search
* [tree traversal] (http://en.wikipedia.org/wiki/Tree_traversal)
* [beam search] (http://en.wikipedia.org/wiki/Beam_search)
* [iterative deepening depth-first search] (http://en.wikipedia.org/wiki/Iterative_deepening_depth-first_search)
* [best-first search] (http://en.wikipedia.org/wiki/Best-first_search)


#### [hill climbing] (http://en.wikipedia.org/wiki/Hill_climbing)
weakness: stops at local max

Why stop if not at a GOAL?
* if we really need a goal, then use beam search with beam width=1
* but some tests do not have explicit goal states, and so we want to max *h*
* if we can generate multiple start nodes, then an excellent algo is to do hill climbing *N* times and keep best(though not a guarantee)
* what if we only have *1* start state?
    * could make *k* random moves, then do hill climbing
    * or could **sometimes** accept bad moves -- simulated annealing

#### [simulated annealing] (http://en.wikipedia.org/wiki/Simulated_annealing)

        // Assume *h* higher is better
        current = start state
        for time = 1 to maxTime
            temp = coolingSchedule(time) // as time higher, temp lower
            if temp == 0:
                return current
            next = randomChildOf(current)
            delta_h = h(next) - h(current)
            if delta_h >= 0:
                current = next // move uphill
            elif random() <= e ** (delta_h / temp):
                current = next // sometimes accept **bad** moves
        return current

        if abs(delta_h) >> temp:
            acceptanceProbability
        if abs(delta_h) << temp:
            acceptanceProbability == 1
        if abs(delta_h) ~~ temp:



### Game
* costs on arcs
* game playing

